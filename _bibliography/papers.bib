---
---

@string{aps = {American Physical Society,}}

@inproceedings{agrawal-etal-2022-large,
  selected={true},
  title = "Large language models are few-shot clinical information extractors",
  author = "Agrawal, Monica  and
    Hegselmann, Stefan  and
    Lang, Hunter  and
    Kim, Yoon  and
    Sontag, David",
  editor = "Goldberg, Yoav  and
    Kozareva, Zornitsa  and
    Zhang, Yue",
  journal = {EMNLP 2022},
  booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
  month = dec,
  year = "2022",
  address = "Abu Dhabi, United Arab Emirates",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2022.emnlp-main.130/",
  doi = "10.18653/v1/2022.emnlp-main.130",
  pages = "1998--2022",
  abstract = "A long-running goal of the clinical NLP community is the extraction of important variables trapped in clinical notes. However, roadblocks have included dataset shift from the general domain and a lack of public clinical corpora and annotations. In this work, we show that large language models, such as InstructGPT (Ouyang et al., 2022), perform well at zero- and few-shot information extraction from clinical text despite not being trained specifically for the clinical domain. Whereas text classification and generation performance have already been studied extensively in such models, here we additionally demonstrate how to leverage them to tackle a diverse set of NLP tasks which require more structured outputs, including span identification, token-level sequence classification, and relation extraction. Further, due to the dearth of available data to evaluate these systems, we introduce new datasets for benchmarking few-shot clinical information extraction based on a manual re-annotation of the CASI dataset (Moon et al., 2014) for new tasks. On the clinical extraction tasks we studied, the GPT-3 systems significantly outperform existing zero- and few-shot baselines.",
  html = {https://aclanthology.org/2022.emnlp-main.130/},
}


@inproceedings{hegselmann2023tabllm,
  selected={true},
  title={Tabllm: Few-shot classification of tabular data with large language models},
  author={Hegselmann, Stefan and Buendia, Alejandro and Lang, Hunter and Agrawal, Monica and Jiang, Xiaoyi and Sontag, David},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={5549--5581},
  year={2023},
  journal={International Conference on Artificial Intelligence and Statistics 2023},
  html = {https://proceedings.mlr.press/v206/hegselmann23a/hegselmann23a.pdf}
}

@article{hegselmann2024data,
  selected={true},
  title={A data-centric approach to generate faithful and high quality patient summaries with large language models},
  author={Hegselmann, Stefan and Shen, Shannon Zejiang and Gierse, Florian and Agrawal, Monica and Sontag, David and Jiang, Xiaoyi},
  journal={Conference on Health, Inference, and Learning 2024},
  year={2024},
  html = {https://raw.githubusercontent.com/mlresearch/v248/main/assets/hegselmann24a/hegselmann24a.pdf}
}